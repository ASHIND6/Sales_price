{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('C:\\\\Users\\\\Ashish2448311\\\\Desktop\\\\nyc-rolling-sales.csv',na_values='?') #read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84548, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #data has 84548 observations and 22 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BUILDING CLASS CATEGORY</th>\n",
       "      <th>TAX CLASS AT PRESENT</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>EASE-MENT</th>\n",
       "      <th>BUILDING CLASS AT PRESENT</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>...</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "      <th>BUILDING CLASS AT TIME OF SALE</th>\n",
       "      <th>SALE PRICE</th>\n",
       "      <th>SALE DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>153 AVENUE B</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1633</td>\n",
       "      <td>6440</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>6625000</td>\n",
       "      <td>2017-07-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>234 EAST 4TH   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616</td>\n",
       "      <td>18690</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "      <td>2016-12-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>39</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>197 EAST 3RD   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212</td>\n",
       "      <td>7803</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "      <td>2016-12-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2B</td>\n",
       "      <td>402</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td>C4</td>\n",
       "      <td>154 EAST 7TH STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2272</td>\n",
       "      <td>6794</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "      <td>3936272</td>\n",
       "      <td>2016-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>404</td>\n",
       "      <td>55</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>301 EAST 10TH   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2369</td>\n",
       "      <td>4615</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>8000000</td>\n",
       "      <td>2016-11-17 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  BOROUGH   NEIGHBORHOOD  \\\n",
       "0           4        1  ALPHABET CITY   \n",
       "1           5        1  ALPHABET CITY   \n",
       "2           6        1  ALPHABET CITY   \n",
       "3           7        1  ALPHABET CITY   \n",
       "4           8        1  ALPHABET CITY   \n",
       "\n",
       "                       BUILDING CLASS CATEGORY TAX CLASS AT PRESENT  BLOCK  \\\n",
       "0  07 RENTALS - WALKUP APARTMENTS                                2A    392   \n",
       "1  07 RENTALS - WALKUP APARTMENTS                                 2    399   \n",
       "2  07 RENTALS - WALKUP APARTMENTS                                 2    399   \n",
       "3  07 RENTALS - WALKUP APARTMENTS                                2B    402   \n",
       "4  07 RENTALS - WALKUP APARTMENTS                                2A    404   \n",
       "\n",
       "   LOT EASE-MENT BUILDING CLASS AT PRESENT                 ADDRESS  \\\n",
       "0    6                                  C2            153 AVENUE B   \n",
       "1   26                                  C7   234 EAST 4TH   STREET   \n",
       "2   39                                  C7   197 EAST 3RD   STREET   \n",
       "3   21                                  C4     154 EAST 7TH STREET   \n",
       "4   55                                  C2  301 EAST 10TH   STREET   \n",
       "\n",
       "          ...          RESIDENTIAL UNITS  COMMERCIAL UNITS  TOTAL UNITS  \\\n",
       "0         ...                          5                 0            5   \n",
       "1         ...                         28                 3           31   \n",
       "2         ...                         16                 1           17   \n",
       "3         ...                         10                 0           10   \n",
       "4         ...                          6                 0            6   \n",
       "\n",
       "   LAND SQUARE FEET  GROSS SQUARE FEET YEAR BUILT TAX CLASS AT TIME OF SALE  \\\n",
       "0              1633               6440       1900                         2   \n",
       "1              4616              18690       1900                         2   \n",
       "2              2212               7803       1900                         2   \n",
       "3              2272               6794       1913                         2   \n",
       "4              2369               4615       1900                         2   \n",
       "\n",
       "   BUILDING CLASS AT TIME OF SALE  SALE PRICE            SALE DATE  \n",
       "0                              C2     6625000  2017-07-19 00:00:00  \n",
       "1                              C7         -    2016-12-14 00:00:00  \n",
       "2                              C7         -    2016-12-09 00:00:00  \n",
       "3                              C4     3936272  2016-09-23 00:00:00  \n",
       "4                              C2     8000000  2016-11-17 00:00:00  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "BOROUGH\n",
      "NEIGHBORHOOD\n",
      "BUILDING CLASS CATEGORY\n",
      "TAX CLASS AT PRESENT\n",
      "BLOCK\n",
      "LOT\n",
      "EASE-MENT\n",
      "BUILDING CLASS AT PRESENT\n",
      "ADDRESS\n",
      "APARTMENT NUMBER\n",
      "ZIP CODE\n",
      "RESIDENTIAL UNITS\n",
      "COMMERCIAL UNITS\n",
      "TOTAL UNITS\n",
      "LAND SQUARE FEET\n",
      "GROSS SQUARE FEET\n",
      "YEAR BUILT\n",
      "TAX CLASS AT TIME OF SALE\n",
      "BUILDING CLASS AT TIME OF SALE\n",
      "SALE PRICE\n",
      "SALE DATE\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Label encoding the categorical features. \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = [ 'NEIGHBORHOOD', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BUILDING CLASS AT PRESENT','BUILDING CLASS AT TIME OF SALE']\n",
    "\n",
    "for x in cols:\n",
    "    lbl = LabelEncoder()\n",
    "    data[x] = lbl.fit_transform(data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0','EASE-MENT','ADDRESS','APARTMENT NUMBER','SALE DATE'],axis=1) #dropping these feautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84548, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BOROUGH                             int64\n",
       "NEIGHBORHOOD                        int64\n",
       "BUILDING CLASS CATEGORY             int64\n",
       "TAX CLASS AT PRESENT                int64\n",
       "BLOCK                               int64\n",
       "LOT                                 int64\n",
       "BUILDING CLASS AT PRESENT           int64\n",
       "ZIP CODE                            int64\n",
       "RESIDENTIAL UNITS                   int64\n",
       "COMMERCIAL UNITS                    int64\n",
       "TOTAL UNITS                         int64\n",
       "LAND SQUARE FEET                  float64\n",
       "GROSS SQUARE FEET                 float64\n",
       "YEAR BUILT                          int64\n",
       "TAX CLASS AT TIME OF SALE           int64\n",
       "BUILDING CLASS AT TIME OF SALE      int64\n",
       "SALE PRICE                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.convert_objects(convert_numeric=True).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = data.rename(columns={'BUILDING CLASS CATEGORY':'BCC', 'TAX CLASS AT PRESENT':'TCAP','BUILDING CLASS AT PRESENT' :'BCAP', 'ZIP CODE':'ZC',\n",
    "                        'RESIDENTIAL UNITS':'RU','COMMERCIAL UNITS' :'CU', 'TOTAL UNITS':'TU', 'LAND SQUARE FEET':'LSF', \n",
    "                        'GROSS SQUARE FEET':'GSF','YEAR BUILT':'YEAR','TAX CLASS AT TIME OF SALE':'TX','BUILDING CLASS AT TIME OF SALE':'BC','SALE PRICE':'TARGET'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting - into NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df_.columns:\n",
    "    df_[i]=pd.to_numeric(df_[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BCC</th>\n",
       "      <th>TCAP</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BCAP</th>\n",
       "      <th>ZC</th>\n",
       "      <th>RU</th>\n",
       "      <th>CU</th>\n",
       "      <th>TU</th>\n",
       "      <th>LSF</th>\n",
       "      <th>GSF</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TX</th>\n",
       "      <th>BC</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>10009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>399</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>10009</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>18690.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>399</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>10009</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>7803.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>402</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>10009</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>6794.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3936272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>404</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>10009</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>4615.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>8000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOROUGH  NEIGHBORHOOD  BCC  TCAP  BLOCK  LOT  BCAP     ZC  RU  CU  TU  \\\n",
       "0        1             1    6     6    392    6    16  10009   5   0   5   \n",
       "1        1             1    6     5    399   26    21  10009  28   3  31   \n",
       "2        1             1    6     5    399   39    21  10009  16   1  17   \n",
       "3        1             1    6     7    402   21    18  10009  10   0  10   \n",
       "4        1             1    6     6    404   55    16  10009   6   0   6   \n",
       "\n",
       "      LSF      GSF  YEAR  TX  BC     TARGET  \n",
       "0  1633.0   6440.0  1900   2  15  6625000.0  \n",
       "1  4616.0  18690.0  1900   2  20        NaN  \n",
       "2  2212.0   7803.0  1900   2  20        NaN  \n",
       "3  2272.0   6794.0  1913   2  17  3936272.0  \n",
       "4  2369.0   4615.0  1900   2  15  8000000.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=df_['TARGET']\n",
    "DF=df_.drop(['TARGET'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH             0\n",
       "NEIGHBORHOOD        0\n",
       "BCC                 0\n",
       "TCAP                0\n",
       "BLOCK               0\n",
       "LOT                 0\n",
       "BCAP                0\n",
       "ZC                  0\n",
       "RU                  0\n",
       "CU                  0\n",
       "TU                  0\n",
       "LSF             26252\n",
       "GSF             27612\n",
       "YEAR                0\n",
       "TX                  0\n",
       "BC                  0\n",
       "TARGET          14561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.isnull().sum() # checking for nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imputing missing values in features with its mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer.fit(DF) \n",
    "df= imputer.transform(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>18690.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>7803.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>6794.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>4615.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3      4     5     6        7     8    9     10      11  \\\n",
       "0  1.0  1.0  6.0  6.0  392.0   6.0  16.0  10009.0   5.0  0.0   5.0  1633.0   \n",
       "1  1.0  1.0  6.0  5.0  399.0  26.0  21.0  10009.0  28.0  3.0  31.0  4616.0   \n",
       "2  1.0  1.0  6.0  5.0  399.0  39.0  21.0  10009.0  16.0  1.0  17.0  2212.0   \n",
       "3  1.0  1.0  6.0  7.0  402.0  21.0  18.0  10009.0  10.0  0.0  10.0  2272.0   \n",
       "4  1.0  1.0  6.0  6.0  404.0  55.0  16.0  10009.0   6.0  0.0   6.0  2369.0   \n",
       "\n",
       "        12      13   14    15  \n",
       "0   6440.0  1900.0  2.0  15.0  \n",
       "1  18690.0  1900.0  2.0  20.0  \n",
       "2   7803.0  1900.0  2.0  20.0  \n",
       "3   6794.0  1913.0  2.0  17.0  \n",
       "4   4615.0  1900.0  2.0  15.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['target']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'BOROUGH',1:'NEIGHBORHOOD',2:'BCC', 3:'TCAP',4:'BLOCK',5:'LOT',6 :'BCAP', 7:'ZC',\n",
    "                        8:'RU',9:'CU', 10:'TU', 11:'LSF', \n",
    "                       12:'GSF',13:'YEAR',14:'TX',15:'BC','target':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BCC</th>\n",
       "      <th>TCAP</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BCAP</th>\n",
       "      <th>ZC</th>\n",
       "      <th>RU</th>\n",
       "      <th>CU</th>\n",
       "      <th>TU</th>\n",
       "      <th>LSF</th>\n",
       "      <th>GSF</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TX</th>\n",
       "      <th>BC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>6794.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3936272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>4615.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3192840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4489.0</td>\n",
       "      <td>18523.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16232000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOROUGH  NEIGHBORHOOD  BCC  TCAP  BLOCK    LOT  BCAP       ZC    RU   CU  \\\n",
       "0      1.0           1.0  6.0   6.0  392.0    6.0  16.0  10009.0   5.0  0.0   \n",
       "3      1.0           1.0  6.0   7.0  402.0   21.0  18.0  10009.0  10.0  0.0   \n",
       "4      1.0           1.0  6.0   6.0  404.0   55.0  16.0  10009.0   6.0  0.0   \n",
       "6      1.0           1.0  6.0   7.0  406.0   32.0  18.0  10009.0   8.0  0.0   \n",
       "9      1.0           1.0  7.0   5.0  387.0  153.0  34.0  10009.0  24.0  0.0   \n",
       "\n",
       "     TU     LSF      GSF    YEAR   TX    BC      target  \n",
       "0   5.0  1633.0   6440.0  1900.0  2.0  15.0   6625000.0  \n",
       "3  10.0  2272.0   6794.0  1913.0  2.0  17.0   3936272.0  \n",
       "4   6.0  2369.0   4615.0  1900.0  2.0  15.0   8000000.0  \n",
       "6   8.0  1750.0   4226.0  1920.0  2.0  17.0   3192840.0  \n",
       "9  24.0  4489.0  18523.0  1920.0  2.0  33.0  16232000.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BCC</th>\n",
       "      <th>TCAP</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BCAP</th>\n",
       "      <th>ZC</th>\n",
       "      <th>RU</th>\n",
       "      <th>CU</th>\n",
       "      <th>TU</th>\n",
       "      <th>LSF</th>\n",
       "      <th>GSF</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TX</th>\n",
       "      <th>BC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>6.998700e+04</td>\n",
       "      <td>6.998700e+04</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>69987.000000</td>\n",
       "      <td>6.998700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.921928</td>\n",
       "      <td>125.886879</td>\n",
       "      <td>7.190678</td>\n",
       "      <td>3.505365</td>\n",
       "      <td>4196.072528</td>\n",
       "      <td>373.828397</td>\n",
       "      <td>46.671239</td>\n",
       "      <td>10741.455185</td>\n",
       "      <td>1.899553</td>\n",
       "      <td>0.172489</td>\n",
       "      <td>2.092203</td>\n",
       "      <td>3.723936e+03</td>\n",
       "      <td>3.788460e+03</td>\n",
       "      <td>1799.348236</td>\n",
       "      <td>1.641976</td>\n",
       "      <td>46.858488</td>\n",
       "      <td>1.276456e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.235688</td>\n",
       "      <td>75.689775</td>\n",
       "      <td>8.241204</td>\n",
       "      <td>2.674934</td>\n",
       "      <td>3429.196524</td>\n",
       "      <td>656.096528</td>\n",
       "      <td>50.319833</td>\n",
       "      <td>1263.234938</td>\n",
       "      <td>14.549545</td>\n",
       "      <td>9.123717</td>\n",
       "      <td>17.276100</td>\n",
       "      <td>3.369980e+04</td>\n",
       "      <td>2.447372e+04</td>\n",
       "      <td>520.884552</td>\n",
       "      <td>0.771162</td>\n",
       "      <td>50.652793</td>\n",
       "      <td>1.140526e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1348.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10306.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.900000e+03</td>\n",
       "      <td>1.268000e+03</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.250000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3378.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11209.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.946000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>1937.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.300000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6186.000000</td>\n",
       "      <td>709.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>11249.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.941676e+03</td>\n",
       "      <td>4.045707e+03</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>9.500000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16319.000000</td>\n",
       "      <td>9106.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>11694.000000</td>\n",
       "      <td>1844.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>4.252327e+06</td>\n",
       "      <td>3.750565e+06</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>2.210000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BOROUGH  NEIGHBORHOOD           BCC          TCAP         BLOCK  \\\n",
       "count  69987.000000  69987.000000  69987.000000  69987.000000  69987.000000   \n",
       "mean       2.921928    125.886879      7.190678      3.505365   4196.072528   \n",
       "std        1.235688     75.689775      8.241204      2.674934   3429.196524   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        2.000000     63.000000      1.000000      1.000000   1348.000000   \n",
       "50%        3.000000    122.000000      6.000000      5.000000   3378.000000   \n",
       "75%        4.000000    195.000000     13.000000      5.000000   6186.000000   \n",
       "max        5.000000    253.000000     46.000000     10.000000  16319.000000   \n",
       "\n",
       "                LOT          BCAP            ZC            RU            CU  \\\n",
       "count  69987.000000  69987.000000  69987.000000  69987.000000  69987.000000   \n",
       "mean     373.828397     46.671239  10741.455185      1.899553      0.172489   \n",
       "std      656.096528     50.319833   1263.234938     14.549545      9.123717   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       22.000000     10.000000  10306.000000      0.000000      0.000000   \n",
       "50%       50.000000     20.000000  11209.000000      1.000000      0.000000   \n",
       "75%      709.000000    119.000000  11249.000000      2.000000      0.000000   \n",
       "max     9106.000000    166.000000  11694.000000   1844.000000   2261.000000   \n",
       "\n",
       "                 TU           LSF           GSF          YEAR            TX  \\\n",
       "count  69987.000000  6.998700e+04  6.998700e+04  69987.000000  69987.000000   \n",
       "mean       2.092203  3.723936e+03  3.788460e+03   1799.348236      1.641976   \n",
       "std       17.276100  3.369980e+04  2.447372e+04    520.884552      0.771162   \n",
       "min        0.000000  0.000000e+00  0.000000e+00      0.000000      1.000000   \n",
       "25%        0.000000  1.900000e+03  1.268000e+03   1920.000000      1.000000   \n",
       "50%        1.000000  2.946000e+03  2.400000e+03   1937.000000      2.000000   \n",
       "75%        2.000000  3.941676e+03  4.045707e+03   1965.000000      2.000000   \n",
       "max     2261.000000  4.252327e+06  3.750565e+06   2017.000000      4.000000   \n",
       "\n",
       "                 BC        target  \n",
       "count  69987.000000  6.998700e+04  \n",
       "mean      46.858488  1.276456e+06  \n",
       "std       50.652793  1.140526e+07  \n",
       "min        0.000000  0.000000e+00  \n",
       "25%        9.000000  2.250000e+05  \n",
       "50%       19.000000  5.300000e+05  \n",
       "75%      119.000000  9.500000e+05  \n",
       "max      165.000000  2.210000e+09  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()#Generates descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6448: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAFKCAYAAAA9hQobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0QUAMAAEQUAMEBEAQAM+P88TxWm/uwIfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"distribution of salary \")\n",
    "sns.distplot(df['target'])\n",
    "plt.legend()\n",
    "plt.show#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to presence of high number of outliers the distribution has high standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping values whose target are 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_0 = df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10228, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=df_0.index.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.drop(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59759, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping values whose sale price are less then 0.15e+07 and greater then 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df[(df['target'] <0.15e+07) & (df['target'] >5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48742, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6448: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAFKCAYAAACZ77LIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"distribution of salary \")\n",
    "sns.distplot(df1['target'])\n",
    "plt.legend()\n",
    "plt.show#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now the distribution looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df1.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df1.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X[['BOROUGH', 'NEIGHBORHOOD', 'BCC', 'TCAP', 'BLOCK', 'LOT', 'BCAP', 'ZC',\n",
    "       'RU', 'CU', 'TU', 'LSF', 'GSF', 'YEAR', 'TX', 'BC']]=scaler.fit_transform(X[['BOROUGH', 'NEIGHBORHOOD', 'BCC', 'TCAP', 'BLOCK', 'LOT', 'BCAP', 'ZC',\n",
    "       'RU', 'CU', 'TU', 'LSF', 'GSF', 'YEAR', 'TX', 'BC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BCC</th>\n",
       "      <th>TCAP</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BCAP</th>\n",
       "      <th>ZC</th>\n",
       "      <th>RU</th>\n",
       "      <th>CU</th>\n",
       "      <th>TU</th>\n",
       "      <th>LSF</th>\n",
       "      <th>GSF</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TX</th>\n",
       "      <th>BC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.855909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.855909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.855909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.855909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.954388</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.855909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.951909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BOROUGH  NEIGHBORHOOD       BCC  TCAP   BLOCK       LOT      BCAP  \\\n",
       "13      0.0      0.003953  0.173913   0.5  0.0228  0.004322  0.120482   \n",
       "15      0.0      0.003953  0.173913   0.5  0.0228  0.004322  0.120482   \n",
       "16      0.0      0.003953  0.173913   0.5  0.0228  0.004322  0.120482   \n",
       "17      0.0      0.003953  0.173913   0.5  0.0228  0.004987  0.120482   \n",
       "18      0.0      0.003953  0.173913   0.5  0.0228  0.005320  0.120482   \n",
       "\n",
       "          ZC   RU   CU   TU       LSF       GSF      YEAR        TX        BC  \n",
       "13  0.855909  0.0  0.0  0.0  0.000932  0.001079  0.951909  0.333333  0.115152  \n",
       "15  0.855909  0.0  0.0  0.0  0.000932  0.001079  0.951909  0.333333  0.115152  \n",
       "16  0.855909  0.0  0.0  0.0  0.000932  0.001079  0.951909  0.333333  0.115152  \n",
       "17  0.855909  0.0  0.0  0.0  0.000932  0.001079  0.954388  0.333333  0.115152  \n",
       "18  0.855909  0.0  0.0  0.0  0.000932  0.001079  0.951909  0.333333  0.115152  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = X.columns\n",
    "x = X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = {}\n",
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Stability Selection via Randomized Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "rlasso = linear_model.RandomizedLasso(alpha=0.01)\n",
    "rlasso.fit(x, Y)\n",
    "ranks[\"rlasso/Stability\"] = ranking(np.abs(rlasso.scores_), colnames)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Recursive Feature Elimination ( RFE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = linear_model.LinearRegression(normalize=True)\n",
    "lr.fit(x,Y)\n",
    "#stop the search when only the last feature is left\n",
    "rfe = RFE(lr, n_features_to_select=1, verbose =3 )\n",
    "rfe.fit(X,Y)\n",
    "ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Linear Model Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(x,Y)\n",
    "ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
    "\n",
    "# Using Ridge \n",
    "ridge = Ridge(alpha = 7)\n",
    "ridge.fit(x,Y)\n",
    "ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
    "\n",
    "# Using Lasso\n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(x, Y)\n",
    "ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Random Forest feature ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100building tree 3 of 100building tree 1 of 100building tree 4 of 100\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 100\n",
      "building tree 8 of 100building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "\n",
      "building tree 9 of 100\n",
      "building tree 11 of 100building tree 10 of 100\n",
      "building tree 12 of 100\n",
      "\n",
      "building tree 13 of 100\n",
      "building tree 16 of 100building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "\n",
      "building tree 17 of 100\n",
      "building tree 20 of 100building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "\n",
      "building tree 21 of 100\n",
      "building tree 24 of 100building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "\n",
      "building tree 25 of 100\n",
      "building tree 28 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 27 of 100\n",
      "building tree 26 of 100building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "\n",
      "building tree 32 of 100\n",
      "building tree 31 of 100building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "\n",
      "building tree 36 of 100\n",
      "building tree 35 of 100building tree 37 of 100\n",
      "building tree 38 of 100\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=100, verbose=3)\n",
    "rf.fit(x,Y)\n",
    "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Feature Ranking MatrixÂ¶\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 41 of 100\n",
      "building tree 39 of 100building tree 40 of 100\n",
      "building tree 42 of 100\n",
      "\n",
      "building tree 46 of 100\n",
      "building tree 43 of 100building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "\n",
      "building tree 50 of 100\n",
      "building tree 47 of 100building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "\n",
      "building tree 54 of 100\n",
      "building tree 51 of 100building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "\n",
      "building tree 58 of 100\n",
      "building tree 55 of 100building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "\n",
      "building tree 61 of 100\n",
      "building tree 59 of 100building tree 60 of 100\n",
      "building tree 62 of 100\n",
      "\n",
      "building tree 65 of 100\n",
      "building tree 63 of 100building tree 64 of 100\n",
      "building tree 66 of 100\n",
      "\n",
      "building tree 69 of 100\n",
      "building tree 67 of 100building tree 68 of 100\n",
      "building tree 70 of 100\n",
      "\n",
      "building tree 73 of 100\n",
      "building tree 71 of 100building tree 72 of 100\n",
      "building tree 74 of 100\n",
      "\n",
      "building tree 76 of 100\n",
      "building tree 75 of 100building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "\n",
      "building tree 80 of 100\n",
      "building tree 79 of 100building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "\n",
      "building tree 84 of 100\n",
      "building tree 83 of 100building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "\n",
      "building tree 88 of 100\n",
      "building tree 87 of 100building tree 89 of 100\n",
      "building tree 91 of 100\n",
      "\n",
      "building tree 93 of 100\n",
      "building tree 90 of 100building tree 92 of 100\n",
      "building tree 94 of 100\n",
      "\n",
      "building tree 97 of 100\n",
      "building tree 95 of 100building tree 96 of 100\n",
      "building tree 98 of 100\n",
      "\n",
      "building tree 100 of 100\n",
      "building tree 99 of 100\n",
      "\n",
      "\tLasso\tLinReg\tRF\tRFE\tRidge\trlasso/Stability\tMean\n",
      "BOROUGH\t0.01\t0.0\t0.27\t0.53\t0.5\t1.0\t0.38\n",
      "NEIGHBORHOOD\t0.0\t0.0\t0.17\t0.13\t0.11\t1.0\t0.24\n",
      "BCC\t0.02\t0.0\t0.11\t0.07\t0.56\t0.0\t0.13\n",
      "TCAP\t0.01\t0.0\t0.03\t0.47\t0.49\t1.0\t0.33\n",
      "BLOCK\t0.02\t0.0\t1.0\t0.67\t0.67\t1.0\t0.56\n",
      "LOT\t0.0\t0.0\t0.52\t0.0\t0.09\t0.0\t0.1\n",
      "BCAP\t0.01\t0.0\t0.07\t0.33\t0.43\t1.0\t0.31\n",
      "ZC\t0.02\t0.0\t0.52\t0.6\t0.67\t1.0\t0.47\n",
      "RU\t1.0\t0.84\t0.22\t0.87\t0.26\t1.0\t0.7\n",
      "CU\t0.55\t1.0\t0.02\t1.0\t0.0\t1.0\t0.6\n",
      "TU\t0.54\t1.0\t0.3\t0.93\t0.21\t1.0\t0.66\n",
      "LSF\t0.42\t0.02\t0.29\t0.73\t0.21\t1.0\t0.44\n",
      "GSF\t0.97\t0.04\t0.38\t0.8\t0.22\t1.0\t0.57\n",
      "YEAR\t0.0\t0.0\t0.32\t0.2\t0.15\t1.0\t0.28\n",
      "TX\t0.0\t0.0\t0.0\t0.27\t0.1\t1.0\t0.23\n",
      "BC\t0.02\t0.0\t0.06\t0.4\t1.0\t1.0\t0.41\n"
     ]
    }
   ],
   "source": [
    "r = {}\n",
    "for name in colnames:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in colnames:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the mean scores into a Pandas dataframe\n",
    "meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n",
    "\n",
    "# Sort the dataframe\n",
    "meanplot = meanplot.sort_values('Mean Ranking', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the mean ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish2448311\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\seaborn\\categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x19a6cff5828>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAQwCAYAAAATlK4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAze2vFehrC16AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the ranking of the features\n",
    "sns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", \n",
    "               size=15, aspect=1, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=df1['target']\n",
    "X = df1.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48742, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA to reduce the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE REATINED: 0.99\n",
      "SHAPE AFTER PCA: (48742, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y2 = scaler.fit_transform(X) #tranform into vecor\n",
    "clf= PCA(.99)   \n",
    "X_trans = clf.fit_transform(y2)\n",
    "print('VARIANCE REATINED:',clf.n_components)\n",
    "#rint(y2.shape)\n",
    "print('SHAPE AFTER PCA:', X_trans.shape) #GIVES US THE SHAPE AFTER PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 215173935816.32 MSE (463868.45) RMSE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "kfold = KFold(n_splits=5, random_state=99)\n",
    "results = cross_val_score(lm, X_trans, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Results: %.2f MSE (%.2f) RMSE\" % (-results.mean(), math.sqrt(-results.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': array([ 30,  50,  70,  90, 110, 130, 150])},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "param_test1 = {'n_estimators':np.arange(30,151,20)}\n",
    "gsearch1 = GridSearchCV(estimator =ensemble.GradientBoostingRegressor(learning_rate=0.1), \n",
    "param_grid = param_test1, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -99444510718.12411, std: 34540887011.13551, params: {'n_estimators': 30},\n",
       "  mean: -97017298452.57123, std: 34987015114.56656, params: {'n_estimators': 50},\n",
       "  mean: -96422723834.61327, std: 34784778295.29319, params: {'n_estimators': 70},\n",
       "  mean: -96240581427.52341, std: 34088297205.04541, params: {'n_estimators': 90},\n",
       "  mean: -95866266148.58932, std: 34586203317.01948, params: {'n_estimators': 110},\n",
       "  mean: -95849755726.91025, std: 35107540658.27805, params: {'n_estimators': 130},\n",
       "  mean: -96182854143.17860, std: 34690607367.47211, params: {'n_estimators': 150}],\n",
       " {'n_estimators': 130},\n",
       " -95849755726.91025)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -99644640760.76854, std: 35115317322.30930, params: {'min_samples_split': 200, 'max_depth': 5},\n",
       "  mean: -102484110611.81351, std: 37574724406.48640, params: {'min_samples_split': 400, 'max_depth': 5},\n",
       "  mean: -98185687566.33525, std: 33015673510.42662, params: {'min_samples_split': 600, 'max_depth': 5},\n",
       "  mean: -98003306097.75696, std: 33389676770.68901, params: {'min_samples_split': 800, 'max_depth': 5},\n",
       "  mean: -99815711977.96152, std: 39999173171.59463, params: {'min_samples_split': 1000, 'max_depth': 5},\n",
       "  mean: -108827966881.00981, std: 48582817776.34645, params: {'min_samples_split': 200, 'max_depth': 7},\n",
       "  mean: -111638350127.52449, std: 59930676827.99511, params: {'min_samples_split': 400, 'max_depth': 7},\n",
       "  mean: -107311564769.88533, std: 51768347512.45438, params: {'min_samples_split': 600, 'max_depth': 7},\n",
       "  mean: -105343574295.02673, std: 44235151757.53831, params: {'min_samples_split': 800, 'max_depth': 7},\n",
       "  mean: -108530006232.54105, std: 42317598518.61184, params: {'min_samples_split': 1000, 'max_depth': 7},\n",
       "  mean: -112216685486.49655, std: 52877686028.11054, params: {'min_samples_split': 200, 'max_depth': 9},\n",
       "  mean: -107744739218.23326, std: 44105683090.48851, params: {'min_samples_split': 400, 'max_depth': 9},\n",
       "  mean: -108221588050.88252, std: 50491802953.01963, params: {'min_samples_split': 600, 'max_depth': 9},\n",
       "  mean: -107469852999.83742, std: 47070495931.67686, params: {'min_samples_split': 800, 'max_depth': 9},\n",
       "  mean: -107063476854.77951, std: 48175036210.82534, params: {'min_samples_split': 1000, 'max_depth': 9},\n",
       "  mean: -109230148610.29964, std: 42279897919.97633, params: {'min_samples_split': 200, 'max_depth': 11},\n",
       "  mean: -112599872039.16870, std: 47979723081.35909, params: {'min_samples_split': 400, 'max_depth': 11},\n",
       "  mean: -107925602631.36102, std: 53835865105.44435, params: {'min_samples_split': 600, 'max_depth': 11},\n",
       "  mean: -106451793322.54863, std: 49926139753.46794, params: {'min_samples_split': 800, 'max_depth': 11},\n",
       "  mean: -114127639213.53049, std: 54298915043.05425, params: {'min_samples_split': 1000, 'max_depth': 11},\n",
       "  mean: -107053078622.22299, std: 38378663150.08590, params: {'min_samples_split': 200, 'max_depth': 13},\n",
       "  mean: -100201394896.42409, std: 36280283383.64242, params: {'min_samples_split': 400, 'max_depth': 13},\n",
       "  mean: -112465455436.08264, std: 54335704118.60002, params: {'min_samples_split': 600, 'max_depth': 13},\n",
       "  mean: -106747360880.51868, std: 48778977994.07447, params: {'min_samples_split': 800, 'max_depth': 13},\n",
       "  mean: -113388958892.28149, std: 54734198712.10030, params: {'min_samples_split': 1000, 'max_depth': 13},\n",
       "  mean: -103996246149.02182, std: 36274657022.05041, params: {'min_samples_split': 200, 'max_depth': 15},\n",
       "  mean: -107656955118.37321, std: 40123750774.15244, params: {'min_samples_split': 400, 'max_depth': 15},\n",
       "  mean: -106372341871.18759, std: 42997871506.35556, params: {'min_samples_split': 600, 'max_depth': 15},\n",
       "  mean: -108752504333.15428, std: 53191006671.70461, params: {'min_samples_split': 800, 'max_depth': 15},\n",
       "  mean: -107353710162.63326, std: 45040170423.62719, params: {'min_samples_split': 1000, 'max_depth': 15}],\n",
       " {'max_depth': 5, 'min_samples_split': 800},\n",
       " -98003306097.75696)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':np.arange(5,16,2), 'min_samples_split':np.arange(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = ensemble.GradientBoostingRegressor(learning_rate=0.1, n_estimators=90), \n",
    "param_grid = param_test2, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_trans,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingRegressor(n_estimators = 130, max_depth = 5,min_samples_split=800,\n",
    "          learning_rate = 0.1, verbose=3, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1 95654447691.0939            6.01s\n",
      "         2 88979536521.6902           17.29s\n",
      "         3 83495424290.1933           25.28s\n",
      "         4 78997089631.5551           26.49s\n",
      "         5 75305761695.6315           27.63s\n",
      "         6 72087679739.9921           27.46s\n",
      "         7 69422268463.5470           27.39s\n",
      "         8 67185480590.2304           27.84s\n",
      "         9 64365026246.1192           31.01s\n",
      "        10 61966581938.5198           31.71s\n",
      "        11 59930375093.7205           32.57s\n",
      "        12 58682438142.3822           32.40s\n",
      "        13 57283163020.1203           33.00s\n",
      "        14 55900638200.4538           33.30s\n",
      "        15 54723098636.6164           32.18s\n",
      "        16 53680961574.2059           32.20s\n",
      "        17 52772347492.3770           31.78s\n",
      "        18 52075414715.1544           31.72s\n",
      "        19 51313221721.3366           32.49s\n",
      "        20 50630793087.6875           31.82s\n",
      "        21 50087796083.7723           31.73s\n",
      "        22 49562257035.7392           31.02s\n",
      "        23 49112135394.0485           30.28s\n",
      "        24 48654293765.0976           30.02s\n",
      "        25 48100218580.1837           29.68s\n",
      "        26 47810799626.0443           29.48s\n",
      "        27 47455503938.9448           29.34s\n",
      "        28 47202331728.5873           28.60s\n",
      "        29 46959706468.3632           27.92s\n",
      "        30 46737869684.4560           27.35s\n",
      "        31 46265434863.7606           26.74s\n",
      "        32 45996431396.1028           26.92s\n",
      "        33 45841561445.5684           26.50s\n",
      "        34 45529178360.5697           26.08s\n",
      "        35 45408327020.9003           25.55s\n",
      "        36 45197229750.1325           25.10s\n",
      "        37 45024601011.4745           24.73s\n",
      "        38 44731195503.8860           24.52s\n",
      "        39 44525016425.8344           24.19s\n",
      "        40 44280086547.5054           23.91s\n",
      "        41 44123365580.5528           23.94s\n",
      "        42 43875497131.2527           23.67s\n",
      "        43 43721365932.5577           23.34s\n",
      "        44 43608350337.5852           23.02s\n",
      "        45 43481265489.6361           22.67s\n",
      "        46 43300949707.4867           22.51s\n",
      "        47 43258775679.2027           22.35s\n",
      "        48 43213896969.7476           22.30s\n",
      "        49 43034683652.6368           21.95s\n",
      "        50 42981499878.1638           21.64s\n",
      "        51 42897075552.5047           21.20s\n",
      "        52 42787790631.3571           20.84s\n",
      "        53 42707297027.1114           20.53s\n",
      "        54 42573090168.8027           20.15s\n",
      "        55 42544270498.8528           19.95s\n",
      "        56 42451195689.2978           19.77s\n",
      "        57 42296180871.7982           19.51s\n",
      "        58 42243077457.7484           19.23s\n",
      "        59 42154763222.6063           18.83s\n",
      "        60 42117087563.6564           18.45s\n",
      "        61 42020880112.2695           18.27s\n",
      "        62 41995370270.5266           17.96s\n",
      "        63 41832674604.7427           17.59s\n",
      "        64 41735438064.9280           17.25s\n",
      "        65 41699001435.9738           16.95s\n",
      "        66 41626268104.5052           16.57s\n",
      "        67 41574318227.3475           16.23s\n",
      "        68 41494705350.4250           15.94s\n",
      "        69 41469858869.5149           15.67s\n",
      "        70 41392543685.9447           15.46s\n",
      "        71 41317906525.4036           15.12s\n",
      "        72 41206582071.5778           14.78s\n",
      "        73 41126010955.6917           14.51s\n",
      "        74 41095083187.2801           14.29s\n",
      "        75 41064358239.4958           14.02s\n",
      "        76 41018331452.3697           13.79s\n",
      "        77 41000560217.5081           13.57s\n",
      "        78 40877464723.7901           13.27s\n",
      "        79 40810784688.5601           12.99s\n",
      "        80 40785913573.4744           12.79s\n",
      "        81 40743323737.0391           12.54s\n",
      "        82 40706212902.2504           12.26s\n",
      "        83 40628103695.7476           12.02s\n",
      "        84 40525198433.9273           11.72s\n",
      "        85 40511966678.8885           11.41s\n",
      "        86 40487234378.0588           11.16s\n",
      "        87 40407508516.4311           10.91s\n",
      "        88 40385265747.0805           10.62s\n",
      "        89 40273065885.8878           10.36s\n",
      "        90 40183931223.8540           10.06s\n",
      "        91 40125059190.2368            9.79s\n",
      "        92 40023602263.2714            9.50s\n",
      "        93 39997231292.5482            9.19s\n",
      "        94 39945782852.8398            8.90s\n",
      "        95 39928496198.0789            8.66s\n",
      "        96 39916642432.1674            8.54s\n",
      "        97 39887605114.9148            8.30s\n",
      "        98 39880233420.8952            8.07s\n",
      "        99 39834882375.4986            7.80s\n",
      "       100 39796106561.1922            7.52s\n",
      "       101 39687400142.1581            7.26s\n",
      "       102 39677818788.5936            7.00s\n",
      "       103 39666114800.4029            6.79s\n",
      "       104 39624540253.2057            6.60s\n",
      "       105 39548323926.1762            6.39s\n",
      "       106 39446682621.2465            6.13s\n",
      "       107 39422629209.9082            5.89s\n",
      "       108 39362750567.6649            5.63s\n",
      "       109 39307433676.2913            5.36s\n",
      "       110 39284124311.4592            5.09s\n",
      "       111 39276365946.3882            4.83s\n",
      "       112 39266555541.8018            4.56s\n",
      "       113 39207067117.6074            4.29s\n",
      "       114 39166535878.1567            4.03s\n",
      "       115 39118829556.8198            3.80s\n",
      "       116 39073777629.3483            3.55s\n",
      "       117 39065755071.6086            3.30s\n",
      "       118 39059637519.7789            3.04s\n",
      "       119 39052958409.9059            2.79s\n",
      "       120 39034104692.2612            2.53s\n",
      "       121 38938417311.7483            2.28s\n",
      "       122 38870853207.7350            2.03s\n",
      "       123 38864873685.5360            1.78s\n",
      "       124 38847693086.5186            1.52s\n",
      "       125 38800401525.4465            1.27s\n",
      "       126 38742311477.7091            1.01s\n",
      "       127 38686206056.1501            0.76s\n",
      "       128 38674816198.2115            0.51s\n",
      "       129 38659963894.1608            0.26s\n",
      "       130 38619756840.5146            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 99701588708.3470            5.76s\n",
      "         2 92462349759.2822           11.77s\n",
      "         3 86461001761.2851           22.99s\n",
      "         4 81605178832.9310           24.63s\n",
      "         5 77439395124.6817           27.48s\n",
      "         6 73902852331.2561           26.08s\n",
      "         7 70797704754.0123           27.24s\n",
      "         8 68394480597.0429           27.92s\n",
      "         9 66200493531.5804           29.71s\n",
      "        10 64165798064.9831           29.87s\n",
      "        11 62389669883.8704           30.30s\n",
      "        12 60957544407.6871           32.70s\n",
      "        13 59795905069.6746           31.69s\n",
      "        14 58831951324.9458           30.23s\n",
      "        15 57857360918.2792           29.02s\n",
      "        16 57072577011.0319           28.13s\n",
      "        17 56329881228.9455           27.38s\n",
      "        18 55571636906.1405           27.10s\n",
      "        19 55061164058.0592           26.34s\n",
      "        20 54552087787.7741           25.76s\n",
      "        21 54139932191.5003           25.50s\n",
      "        22 53644477530.8758           24.93s\n",
      "        23 53272100886.0447           26.16s\n",
      "        24 52965959560.4187           26.14s\n",
      "        25 52574714420.5865           26.85s\n",
      "        26 52329236110.6179           27.15s\n",
      "        27 51972740141.1276           27.15s\n",
      "        28 51633613459.8344           26.76s\n",
      "        29 51480104237.1695           27.32s\n",
      "        30 51259765891.5979           28.68s\n",
      "        31 50917179737.6869           28.79s\n",
      "        32 50749519439.2401           28.69s\n",
      "        33 50472974589.5767           28.21s\n",
      "        34 50288663017.1221           27.58s\n",
      "        35 50093989688.2748           27.34s\n",
      "        36 49915676927.6761           27.24s\n",
      "        37 49666179689.1406           27.29s\n",
      "        38 49479621208.8620           27.02s\n",
      "        39 49362533198.0288           26.75s\n",
      "        40 49148094728.2533           26.47s\n",
      "        41 49051386400.0589           25.80s\n",
      "        42 48891033740.7736           25.39s\n",
      "        43 48778186023.1839           25.20s\n",
      "        44 48679170594.1209           24.66s\n",
      "        45 48597785114.0415           24.07s\n",
      "        46 48502543075.4464           23.53s\n",
      "        47 48374930152.3572           23.09s\n",
      "        48 48306622670.4039           22.98s\n",
      "        49 48173643459.4556           22.79s\n",
      "        50 48026252035.7682           22.35s\n",
      "        51 47971883737.9971           21.87s\n",
      "        52 47816912320.4848           21.45s\n",
      "        53 47708230705.8305           21.07s\n",
      "        54 47597741493.6289           20.68s\n",
      "        55 47503033618.0718           20.39s\n",
      "        56 47391903940.0080           20.11s\n",
      "        57 47365181229.5956           19.99s\n",
      "        58 47310696141.0508           19.56s\n",
      "        59 47247992702.5108           19.33s\n",
      "        60 47093053870.9716           18.92s\n",
      "        61 46973072418.3902           18.56s\n",
      "        62 46888186706.8256           18.20s\n",
      "        63 46830138466.8458           17.81s\n",
      "        64 46800837407.6873           17.38s\n",
      "        65 46641666108.5643           17.06s\n",
      "        66 46535670274.5834           16.82s\n",
      "        67 46510668509.5264           16.48s\n",
      "        68 46476493221.6546           16.16s\n",
      "        69 46430632553.6479           15.83s\n",
      "        70 46327559981.5300           15.58s\n",
      "        71 46298362151.4554           15.24s\n",
      "        72 46278064658.5839           14.92s\n",
      "        73 46128703596.4495           14.62s\n",
      "        74 46115689626.9250           14.38s\n",
      "        75 46074033234.5152           14.09s\n",
      "        76 46056964460.1579           13.75s\n",
      "        77 46025862081.8987           13.44s\n",
      "        78 45944834708.0657           13.16s\n",
      "        79 45886124058.1145           12.87s\n",
      "        80 45867264107.5601           12.57s\n",
      "        81 45837911376.1356           12.33s\n",
      "        82 45743793775.2156           12.09s\n",
      "        83 45723123000.5544           11.83s\n",
      "        84 45649123074.6267           11.73s\n",
      "        85 45582953745.5937           11.45s\n",
      "        86 45572278271.0511           11.18s\n",
      "        87 45542104695.7770           10.86s\n",
      "        88 45525813739.7962           10.56s\n",
      "        89 45420851721.6136           10.26s\n",
      "        90 45398623075.6692           10.05s\n",
      "        91 45380932598.6697            9.88s\n",
      "        92 45265743403.2825            9.72s\n",
      "        93 45184164739.6007            9.53s\n",
      "        94 45177061879.4899            9.24s\n",
      "        95 45169131581.3373            9.06s\n",
      "        96 45117203597.9348            8.77s\n",
      "        97 45007173421.4521            8.50s\n",
      "        98 44996433244.4000            8.24s\n",
      "        99 44966909317.4277            8.03s\n",
      "       100 44879514020.8023            7.75s\n",
      "       101 44866315756.7689            7.51s\n",
      "       102 44853754204.2955            7.26s\n",
      "       103 44846628138.7481            7.06s\n",
      "       104 44797076101.2719            6.79s\n",
      "       105 44781579447.6578            6.50s\n",
      "       106 44747316921.2832            6.22s\n",
      "       107 44727745457.6033            5.95s\n",
      "       108 44676645688.6929            5.67s\n",
      "       109 44604434944.2815            5.40s\n",
      "       110 44569873538.4514            5.15s\n",
      "       111 44563859358.8408            4.89s\n",
      "       112 44513001005.3617            4.66s\n",
      "       113 44413198349.7258            4.41s\n",
      "       114 44395180400.0690            4.18s\n",
      "       115 44378048551.6620            3.95s\n",
      "       116 44335019746.2125            3.68s\n",
      "       117 44310014470.6744            3.40s\n",
      "       118 44237461513.9504            3.13s\n",
      "       119 44199291282.8322            2.86s\n",
      "       120 44163038155.7120            2.60s\n",
      "       121 44069986775.7908            2.34s\n",
      "       122 44006014706.9573            2.07s\n",
      "       123 43974736141.2474            1.81s\n",
      "       124 43963885984.4562            1.55s\n",
      "       125 43937772709.4432            1.30s\n",
      "       126 43930957678.2442            1.04s\n",
      "       127 43917620716.9239            0.79s\n",
      "       128 43891739636.6465            0.52s\n",
      "       129 43857667614.2299            0.26s\n",
      "       130 43836896238.8288            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 99061870630.3797            5.05s\n",
      "         2 92258884613.4811           31.24s\n",
      "         3 86701293810.1727           31.77s\n",
      "         4 82191852751.7800           30.44s\n",
      "         5 78190688077.3942           29.39s\n",
      "         6 74929584500.0337           29.99s\n",
      "         7 72435892356.2138           32.02s\n",
      "         8 69928270243.6072           34.20s\n",
      "         9 67467947704.6409           36.77s\n",
      "        10 65719062568.7675           35.25s\n",
      "        11 63895581505.6998           34.89s\n",
      "        12 62394226536.1954           33.74s\n",
      "        13 60827830517.8820           32.82s\n",
      "        14 59535049425.0793           32.08s\n",
      "        15 58504019429.4855           31.28s\n",
      "        16 57550532371.2422           30.17s\n",
      "        17 56716141184.3259           30.67s\n",
      "        18 56088354915.8422           30.03s\n",
      "        19 55446142860.3200           29.47s\n",
      "        20 54960720358.5176           28.80s\n",
      "        21 54534907493.8865           28.17s\n",
      "        22 54126291128.1823           27.61s\n",
      "        23 53658160968.3250           27.03s\n",
      "        24 53244513204.9826           26.76s\n",
      "        25 52944931887.3623           26.43s\n",
      "        26 52650468630.6959           26.28s\n",
      "        27 52239518754.9646           26.43s\n",
      "        28 51830728333.2805           25.85s\n",
      "        29 51600511911.1377           25.30s\n",
      "        30 51226404728.7301           25.50s\n",
      "        31 50881934038.9193           25.99s\n",
      "        32 50758299043.5543           25.56s\n",
      "        33 50566725477.8579           25.01s\n",
      "        34 50407645542.3905           24.50s\n",
      "        35 50229744826.2118           24.01s\n",
      "        36 50162268664.9055           23.99s\n",
      "        37 49987187031.5769           23.65s\n",
      "        38 49910430754.6241           23.31s\n",
      "        39 49687269125.2032           23.11s\n",
      "        40 49619145443.8605           22.84s\n",
      "        41 49343104836.2317           22.96s\n",
      "        42 49303358879.9365           22.59s\n",
      "        43 49129051613.5747           22.51s\n",
      "        44 49081844131.8137           22.44s\n",
      "        45 49002765091.7639           22.32s\n",
      "        46 48838527100.6157           21.86s\n",
      "        47 48774514932.9194           21.48s\n",
      "        48 48710257864.0073           21.11s\n",
      "        49 48614076297.3178           21.26s\n",
      "        50 48539809139.8899           21.12s\n",
      "        51 48503593653.6429           20.87s\n",
      "        52 48336114078.2423           20.54s\n",
      "        53 48304502631.6500           20.36s\n",
      "        54 48253248744.1179           20.24s\n",
      "        55 48230170336.1254           20.01s\n",
      "        56 48194672585.1189           19.58s\n",
      "        57 48009721041.4059           19.23s\n",
      "        58 47812276230.8881           18.91s\n",
      "        59 47695217862.0478           18.63s\n",
      "        60 47645797080.6459           18.33s\n",
      "        61 47593847359.1774           18.06s\n",
      "        62 47426021265.9488           17.83s\n",
      "        63 47387729388.1306           17.53s\n",
      "        64 47348061578.7919           17.30s\n",
      "        65 47195573224.4288           16.96s\n",
      "        66 47139432298.5944           16.80s\n",
      "        67 47055468099.3006           16.58s\n",
      "        68 46989322661.4475           16.41s\n",
      "        69 46919256843.8076           16.20s\n",
      "        70 46897747041.8693           15.89s\n",
      "        71 46855761766.5059           15.83s\n",
      "        72 46772090250.5724           15.61s\n",
      "        73 46674902339.2263           15.50s\n",
      "        74 46636897157.0768           15.18s\n",
      "        75 46606686659.4770           14.84s\n",
      "        76 46591558938.8000           14.48s\n",
      "        77 46518576405.8873           14.15s\n",
      "        78 46462286425.8302           13.78s\n",
      "        79 46426476394.9702           13.47s\n",
      "        80 46359045007.8367           13.17s\n",
      "        81 46271323842.1779           13.01s\n",
      "        82 46253888073.6124           12.76s\n",
      "        83 46225187962.2433           12.50s\n",
      "        84 46128252668.7334           12.29s\n",
      "        85 46074333831.3812           11.98s\n",
      "        86 46019399707.8499           11.73s\n",
      "        87 46008840034.3351           11.51s\n",
      "        88 46000424057.5294           11.25s\n",
      "        89 45922086176.4732           11.02s\n",
      "        90 45865937533.3681           10.77s\n",
      "        91 45753649652.7431           10.51s\n",
      "        92 45694111130.8801           10.21s\n",
      "        93 45586880258.0471            9.96s\n",
      "        94 45505817919.8100            9.70s\n",
      "        95 45489178129.4648            9.47s\n",
      "        96 45479724947.7095            9.17s\n",
      "        97 45434598204.6142            8.87s\n",
      "        98 45343564456.6692            8.57s\n",
      "        99 45319374277.0852            8.30s\n",
      "       100 45298669551.8139            8.05s\n",
      "       101 45248985273.5500            7.78s\n",
      "       102 45173728318.8293            7.51s\n",
      "       103 45166192258.3179            7.29s\n",
      "       104 45144604647.1820            7.08s\n",
      "       105 45059978218.7931            6.83s\n",
      "       106 45011362755.5830            6.56s\n",
      "       107 44975701126.6554            6.30s\n",
      "       108 44939652097.8827            6.03s\n",
      "       109 44917203955.0058            5.78s\n",
      "       110 44897656100.0984            5.50s\n",
      "       111 44891187486.5319            5.20s\n",
      "       112 44845574722.3046            4.91s\n",
      "       113 44781781986.4756            4.65s\n",
      "       114 44737025279.2833            4.36s\n",
      "       115 44701720743.0994            4.09s\n",
      "       116 44645048241.6254            3.81s\n",
      "       117 44605941396.3605            3.54s\n",
      "       118 44586421163.1230            3.27s\n",
      "       119 44497325168.7840            2.99s\n",
      "       120 44415801125.7271            2.72s\n",
      "       121 44364437684.1039            2.45s\n",
      "       122 44316300704.3998            2.17s\n",
      "       123 44268888948.0885            1.90s\n",
      "       124 44253031314.9857            1.63s\n",
      "       125 44246960351.7256            1.36s\n",
      "       126 44237873376.3950            1.09s\n",
      "       127 44219846615.8633            0.82s\n",
      "       128 44149264482.6404            0.54s\n",
      "       129 44144782377.8157            0.27s\n",
      "       130 44121424250.0231            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 105111703894.7247            5.49s\n",
      "         2 98308573549.7390           13.68s\n",
      "         3 92628442035.0161           24.40s\n",
      "         4 87988238619.2112           31.52s\n",
      "         5 83642603508.0259           30.48s\n",
      "         6 80302412852.7686           35.43s\n",
      "         7 77102563848.4867           32.74s\n",
      "         8 74434555598.9482           32.08s\n",
      "         9 72285899264.7171           31.17s\n",
      "        10 70393213900.9807           29.99s\n",
      "        11 68576330813.6742           31.61s\n",
      "        12 67148882578.1439           30.32s\n",
      "        13 65768900778.4545           29.46s\n",
      "        14 64670697910.4098           28.62s\n",
      "        15 63667606686.4735           28.06s\n",
      "        16 62992939890.9879           27.34s\n",
      "        17 62093349507.4274           27.32s\n",
      "        18 61447905085.4934           27.02s\n",
      "        19 60755636916.3130           26.93s\n",
      "        20 60340703214.3323           26.65s\n",
      "        21 59715498009.6615           26.53s\n",
      "        22 59186500420.1895           26.22s\n",
      "        23 58913553710.9326           26.06s\n",
      "        24 58521341947.3173           26.10s\n",
      "        25 58094087609.3102           25.78s\n",
      "        26 57831338038.7305           25.12s\n",
      "        27 57357260365.3627           24.76s\n",
      "        28 57145469700.6147           24.21s\n",
      "        29 56838068326.5357           23.71s\n",
      "        30 56598802620.8626           23.29s\n",
      "        31 56428755412.6595           22.79s\n",
      "        32 56162277127.0487           22.66s\n",
      "        33 55938554014.1703           22.57s\n",
      "        34 55845099435.5491           22.77s\n",
      "        35 55713107519.0120           22.44s\n",
      "        36 55557563745.2454           22.25s\n",
      "        37 55427707369.5092           22.16s\n",
      "        38 55257664099.6661           21.82s\n",
      "        39 55201777597.3498           21.39s\n",
      "        40 55121497119.0848           21.06s\n",
      "        41 55021275688.5149           20.80s\n",
      "        42 54896858108.1959           20.54s\n",
      "        43 54792256729.0494           20.22s\n",
      "        44 54656601930.0674           19.90s\n",
      "        45 54556618874.7954           19.74s\n",
      "        46 54385226831.8085           19.48s\n",
      "        47 54300779505.4593           19.28s\n",
      "        48 54176338653.8559           19.35s\n",
      "        49 54055015846.3715           19.08s\n",
      "        50 53979696816.7018           18.82s\n",
      "        51 53906700422.3602           18.55s\n",
      "        52 53807360356.0178           18.18s\n",
      "        53 53781490673.8989           17.84s\n",
      "        54 53684279290.1344           17.49s\n",
      "        55 53521852957.2243           17.17s\n",
      "        56 53471932304.8251           16.93s\n",
      "        57 53350538418.3356           16.62s\n",
      "        58 53312502829.0046           16.36s\n",
      "        59 53286530280.4652           16.07s\n",
      "        60 53211198704.6957           16.03s\n",
      "        61 53134491427.6892           15.80s\n",
      "        62 53088225117.9576           15.65s\n",
      "        63 53035835826.9880           15.39s\n",
      "        64 52969280959.3792           15.46s\n",
      "        65 52898058867.0771           15.16s\n",
      "        66 52867733152.7661           15.15s\n",
      "        67 52807111458.5869           14.86s\n",
      "        68 52712673227.2299           14.68s\n",
      "        69 52681425891.7797           14.58s\n",
      "        70 52608898015.0802           14.63s\n",
      "        71 52534585337.7044           14.43s\n",
      "        72 52443739389.4923           14.12s\n",
      "        73 52426648977.6869           13.79s\n",
      "        74 52414501428.8485           13.50s\n",
      "        75 52389086433.6202           13.20s\n",
      "        76 52331589021.2836           12.91s\n",
      "        77 52256569435.6430           12.67s\n",
      "        78 52245373159.4776           12.35s\n",
      "        79 52181600908.5010           12.11s\n",
      "        80 52126824725.5587           11.92s\n",
      "        81 52032608253.8686           11.71s\n",
      "        82 51975851315.6840           11.51s\n",
      "        83 51879394607.1646           11.26s\n",
      "        84 51808582720.9892           10.98s\n",
      "        85 51799528696.8675           10.75s\n",
      "        86 51747476146.5626           10.53s\n",
      "        87 51697032673.7858           10.32s\n",
      "        88 51643915584.9725           10.13s\n",
      "        89 51602112128.7802            9.87s\n",
      "        90 51535243773.1096            9.62s\n",
      "        91 51443415559.2269            9.46s\n",
      "        92 51390317640.6837            9.18s\n",
      "        93 51347319186.2304            8.96s\n",
      "        94 51252233319.4449            8.73s\n",
      "        95 51218532202.8156            8.45s\n",
      "        96 51149417552.8979            8.22s\n",
      "        97 51078328236.2773            7.97s\n",
      "        98 51025016091.3513            7.77s\n",
      "        99 50984954397.8437            7.54s\n",
      "       100 50976617226.4046            7.28s\n",
      "       101 50967669583.1366            7.01s\n",
      "       102 50907962493.6694            6.74s\n",
      "       103 50867176153.0429            6.50s\n",
      "       104 50806693215.0498            6.26s\n",
      "       105 50727953717.9422            6.03s\n",
      "       106 50708270151.1343            5.77s\n",
      "       107 50618627599.9207            5.52s\n",
      "       108 50602479423.4292            5.31s\n",
      "       109 50595081806.3208            5.05s\n",
      "       110 50577463318.0060            4.80s\n",
      "       111 50505651163.2510            4.54s\n",
      "       112 50386441286.4984            4.31s\n",
      "       113 50376654284.4121            4.09s\n",
      "       114 50362229048.0643            3.87s\n",
      "       115 50299712071.0831            3.64s\n",
      "       116 50260844601.8273            3.40s\n",
      "       117 50254018137.3181            3.17s\n",
      "       118 50194106470.2166            2.92s\n",
      "       119 50165113989.3558            2.68s\n",
      "       120 50058757283.5820            2.44s\n",
      "       121 50023770466.7643            2.19s\n",
      "       122 50003107575.8950            1.95s\n",
      "       123 49988308975.4608            1.71s\n",
      "       124 49978185782.5553            1.46s\n",
      "       125 49972436789.9915            1.21s\n",
      "       126 49965694442.4042            0.97s\n",
      "       127 49852064283.3038            0.73s\n",
      "       128 49835244212.7609            0.49s\n",
      "       129 49816840718.5587            0.24s\n",
      "       130 49811285487.5703            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1 112817710390.6021            5.24s\n",
      "         2 105151016380.1526           18.68s\n",
      "         3 98332498963.2461           26.47s\n",
      "         4 92809905528.9112           25.22s\n",
      "         5 88265823305.2126           24.48s\n",
      "         6 84643607036.0196           26.30s\n",
      "         7 81452541099.9610           27.91s\n",
      "         8 78682690737.9054           26.58s\n",
      "         9 76454400582.9398           25.29s\n",
      "        10 74440079074.8315           25.01s\n",
      "        11 72828922317.3291           25.17s\n",
      "        12 71227169207.9590           25.81s\n",
      "        13 69963280446.8961           26.48s\n",
      "        14 68877417524.6523           26.19s\n",
      "        15 67672999610.1420           25.35s\n",
      "        16 66804706455.0416           25.99s\n",
      "        17 65907420109.8998           25.77s\n",
      "        18 65015249307.3239           26.03s\n",
      "        19 64132382019.6616           25.67s\n",
      "        20 63582274540.1012           25.64s\n",
      "        21 62871725090.6304           24.98s\n",
      "        22 62205266541.7937           24.82s\n",
      "        23 61689982551.7862           24.28s\n",
      "        24 61369044736.4732           23.83s\n",
      "        25 60969902117.1720           23.55s\n",
      "        26 60697103466.0136           23.34s\n",
      "        27 60264472594.8076           23.27s\n",
      "        28 60011280630.6169           23.19s\n",
      "        29 59809080910.7211           22.74s\n",
      "        30 59586958848.8617           22.23s\n",
      "        31 59177756849.8814           22.40s\n",
      "        32 58857373664.1494           22.39s\n",
      "        33 58751963203.0330           21.97s\n",
      "        34 58476351006.1241           22.23s\n",
      "        35 58322078513.3702           22.15s\n",
      "        36 58130637202.2300           22.12s\n",
      "        37 58055716760.9457           21.78s\n",
      "        38 57832365687.5845           21.44s\n",
      "        39 57677330153.8793           21.21s\n",
      "        40 57448717149.2313           20.95s\n",
      "        41 57396720997.4710           20.60s\n",
      "        42 57348263297.1377           20.18s\n",
      "        43 57214232673.6115           19.94s\n",
      "        44 56973007541.8395           19.63s\n",
      "        45 56873318887.7810           19.33s\n",
      "        46 56833773349.1529           18.93s\n",
      "        47 56768247411.3167           18.65s\n",
      "        48 56503543837.6212           18.53s\n",
      "        49 56413827265.0884           18.33s\n",
      "        50 56337686696.5189           18.04s\n",
      "        51 56182732980.2003           17.78s\n",
      "        52 56138866169.4372           17.63s\n",
      "        53 56035558060.6906           17.32s\n",
      "        54 56000436055.4595           17.21s\n",
      "        55 55886574291.5700           17.04s\n",
      "        56 55848680290.3012           16.91s\n",
      "        57 55825289308.1639           16.87s\n",
      "        58 55780038206.5519           16.62s\n",
      "        59 55616682386.3071           16.38s\n",
      "        60 55570623116.8738           16.06s\n",
      "        61 55478666892.0906           15.86s\n",
      "        62 55308118333.5819           16.00s\n",
      "        63 55234034237.4325           15.72s\n",
      "        64 55100607543.5739           15.48s\n",
      "        65 55075086560.8328           15.23s\n",
      "        66 55011142131.8258           14.98s\n",
      "        67 54919538875.5750           14.80s\n",
      "        68 54862896911.3327           14.57s\n",
      "        69 54809658671.6093           14.35s\n",
      "        70 54705013810.0910           14.09s\n",
      "        71 54644769882.3675           13.84s\n",
      "        72 54551642659.9687           13.55s\n",
      "        73 54494540894.0559           13.27s\n",
      "        74 54415512093.6473           13.00s\n",
      "        75 54400342860.0266           12.75s\n",
      "        76 54306498225.7276           12.51s\n",
      "        77 54288303558.5210           12.30s\n",
      "        78 54221451175.8066           12.04s\n",
      "        79 54157020720.0364           11.79s\n",
      "        80 54142521611.8368           11.70s\n",
      "        81 54129984602.1187           11.47s\n",
      "        82 54100765077.5000           11.24s\n",
      "        83 54008454320.2025           10.99s\n",
      "        84 53930089053.8401           10.71s\n",
      "        85 53863554115.2553           10.43s\n",
      "        86 53802072375.5931           10.25s\n",
      "        87 53749209690.7469            9.97s\n",
      "        88 53738161854.7784            9.87s\n",
      "        89 53689311200.0500            9.67s\n",
      "        90 53650860683.3793            9.42s\n",
      "        91 53640913756.7434            9.15s\n",
      "        92 53561017380.5184            8.97s\n",
      "        93 53451044632.8102            8.92s\n",
      "        94 53376685139.9464            8.71s\n",
      "        95 53339514231.1119            8.45s\n",
      "        96 53324216846.6506            8.23s\n",
      "        97 53207904319.5290            8.01s\n",
      "        98 53073049261.6597            7.77s\n",
      "        99 53064491131.1891            7.52s\n",
      "       100 53055275367.9803            7.31s\n",
      "       101 53017596103.5700            7.06s\n",
      "       102 52944500480.2842            6.84s\n",
      "       103 52897085711.6062            6.64s\n",
      "       104 52879636408.3260            6.36s\n",
      "       105 52866930426.8057            6.13s\n",
      "       106 52831126508.8552            5.89s\n",
      "       107 52804064130.2379            5.67s\n",
      "       108 52758970125.2566            5.42s\n",
      "       109 52751974263.5768            5.17s\n",
      "       110 52722828024.7127            4.92s\n",
      "       111 52714651364.5496            4.67s\n",
      "       112 52705701662.3747            4.45s\n",
      "       113 52693763871.2206            4.20s\n",
      "       114 52665415424.2371            3.95s\n",
      "       115 52635427038.2690            3.71s\n",
      "       116 52594338409.1354            3.47s\n",
      "       117 52536410098.4210            3.22s\n",
      "       118 52530789059.1411            2.96s\n",
      "       119 52482327657.9713            2.72s\n",
      "       120 52414122411.9920            2.47s\n",
      "       121 52376787184.6916            2.22s\n",
      "       122 52297378213.5742            1.97s\n",
      "       123 52275264928.4629            1.73s\n",
      "       124 52262779415.1105            1.48s\n",
      "       125 52203138396.0368            1.24s\n",
      "       126 52141466706.9858            0.99s\n",
      "       127 52103289956.1237            0.74s\n",
      "       128 52030916713.2273            0.49s\n",
      "       129 52018435922.5834            0.25s\n",
      "       130 52008644943.6398            0.00s\n",
      "Results: 114395985335.95 MSE (338224.76) RMSE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=5, random_state=99)\n",
    "results = cross_val_score(clf, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Results: %.2f MSE (%.2f) RMSE\" % (-results.mean(), math.sqrt(-results.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) FULLY CONNECTED NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = df1.shape[0]\n",
    "p = df1.shape[1]\n",
    "data = df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end + 1\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9748,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a and b as placeholders\n",
    "a = tf.placeholder(dtype=tf.int8)\n",
    "b = tf.placeholder(dtype=tf.int8)\n",
    "\n",
    "# Define the addition\n",
    "c = tf.add(a, b)\n",
    "\n",
    "# Initialize the graph\n",
    "graph = tf.Session()\n",
    "\n",
    "# Run the graph\n",
    "graph.run(c, feed_dict={a: 5, b: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model architecture parameters\n",
    "n_features = 16\n",
    "n_neurons_1 = 256\n",
    "n_neurons_2 = 128\n",
    "n_neurons_3 = 64\n",
    "n_neurons_4 = 36\n",
    "n_target = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_features])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 1: Variables for hidden weights and biases\n",
    "W_hidden_1 = tf.Variable(tf.random_normal([n_features, n_neurons_1]),name=\"weights\")\n",
    "bias_hidden_1 = tf.Variable(tf.random_normal([n_neurons_1]),name=\"biases\")\n",
    "# Layer 2: Variables for hidden weights and biases\n",
    "W_hidden_2 = tf.Variable(tf.random_normal([n_neurons_1, n_neurons_2]),name=\"weights\")\n",
    "bias_hidden_2 = tf.Variable(tf.random_normal([n_neurons_2]),name=\"biases\")\n",
    "# Layer 3: Variables for hidden weights and biases\n",
    "W_hidden_3 = tf.Variable(tf.random_normal([n_neurons_2, n_neurons_3]),name=\"weights\")\n",
    "bias_hidden_3 = tf.Variable(tf.random_normal([n_neurons_3]),name=\"biases\")\n",
    "# Layer 4: Variables for hidden weights and biases\n",
    "W_hidden_4 = tf.Variable(tf.random_normal([n_neurons_3, n_neurons_4]),name=\"weights\")\n",
    "bias_hidden_4 = tf.Variable(tf.random_normal([n_neurons_4]),name=\"biases\")\n",
    "\n",
    "# Output layer: Variables for output weights and biases\n",
    "W_out = tf.Variable(tf.random_normal([n_neurons_4, n_target]),name=\"weights\")\n",
    "bias_out = tf.Variable(tf.random_normal([n_target]),name=\"biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160086780.0\n"
     ]
    }
   ],
   "source": [
    "# Make Session\n",
    "net = tf.Session()\n",
    "# Run initializer\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "# Number of epochs and batch size\n",
    "epochs = 1000\n",
    "batch_size = 256\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 5) == 0:\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: X_test})\n",
    "            \n",
    "            \n",
    "\n",
    "# Print final MSE after Training\n",
    "mse_final = net.run(mse, feed_dict={X: X_test, Y: y_test})\n",
    "saver.save(net, \"checkpoint/sale_price.ckpt\")\n",
    "print(mse_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12652.540614437876"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.sqrt(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
